{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb7adbc",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "__[1. Introduction](#Introduction)__  \n",
    "\n",
    "__[2. Loading modules and data](#Loading-modules-and-data)__  \n",
    "\n",
    "__[3. Preprocessing](#Preprocessing)__  \n",
    "\n",
    "__[4. Exploratory analysis and feature engineering](#Exploratory-analysis-and-feature-engineering)__  \n",
    "    [4.1. Profiling variables](#Profiling-variables)  \n",
    "    [4.1. Data transformation and Clustering variables](#Data-transformation-and-Clustering-variables)\n",
    "\n",
    "__[4. Model Selection](#Model-Selection)__  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a8cd8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Clustering is an unsupervised machine learning task, involving discovering groups in data. Clustering helps with pattern discovery. This project aims to use clustering approaches to perform customer segmentation on [Online Retail data](https://www.kaggle.com/datasets/vijayuv/onlineretail).\n",
    "\n",
    "\n",
    "### Use cases:\n",
    "- __data summarization__\n",
    "    - clustering is a step for classification or outlier analysis\n",
    "    - dimensionality reduction\n",
    "- __collaborative filtering__\n",
    "    - grouping of users with similar interests\n",
    "- __customer segmentation__\n",
    "    - grouping of customers\n",
    "- __dynamic trend detection__\n",
    "    - in social networks:  data is dynamically clustered in a streaming fashion and used to determine patterns of changes.\n",
    "- __multimedia data analysis__\n",
    "    - detecting similar areas in images, video, audio.\n",
    "- __social network analysis__\n",
    "    - detecting communities\n",
    "    \n",
    "### Validation  \n",
    "- use __case studies__ to illustrate the subjective quality of the clusters\n",
    "- __measures of the clusters__ (cluster radius or density)\n",
    "    - can be biased (measures could favor different algorithms in a different way)\n",
    "- labels can be given to data points - then __correlations of the clusters with the labels__ can be used\n",
    "    - class labels may not always align with the natural clusters\n",
    "    \n",
    "    \n",
    "### Approach\n",
    "\n",
    "1. Define goals: find users that are similar in important ways to the business (producs, usage, demographics, channels, etc) and:\n",
    "    - discover how business metrics differ between them.\n",
    "    - use that information to improve existing models.\n",
    "    - tailor marketing strategy to each customer segment.\n",
    "    \n",
    "    \n",
    "2. Data:\n",
    "    1. Behavioural data (transactions):\n",
    "        - visits, usage, penetration responses, engagement, lifestyle, preferences, channel preferences, etc.\n",
    "        - number of times a user purchased, how much, what products and categories.\n",
    "        - number of transactions over a period of time, number of units.\n",
    "    1. Additional data:\n",
    "        1. User side:\n",
    "            - time between purchases, categories purchased, peaks and valleys of transactions, units and revenue, share of categories, number of units and transactions per user, percentage of discounts per user, top N categories purchased per user.\n",
    "        1. Company side:\n",
    "            - seasonality variables, featured categories, promotions in place.\n",
    "        1. Third party data:\n",
    "            - demographics, interests, attitudes, lifestyles.\n",
    "    \n",
    "\n",
    "3. Implement a model:\n",
    "    - model should be multivariate, multivariable, probabilistic (e.g. LCA).\n",
    "    - run model (e.g. linear regression) for each segment separately, thus taking into account different user profiles.\n",
    "\n",
    "\n",
    "4. Analyse returned segments:\n",
    "    - some segments could be price sensitive, prefer one channel, have high penetration of a particular product, prefer a certain way of communication.\n",
    "    - we expect to find a segment that is penetrated in one category, but not another.\n",
    "    - profiling:\n",
    "        - profile - what is shown to managers as a proof that the segments are different: \n",
    "            - KPIs.\n",
    "            - indexes (e.g. take each segment's mean and divide by total mean to show how a segment is different from the rest in percentage).\n",
    "    - name the segments (e.g. high revenue, low response, etc.)\n",
    "    \n",
    "    \n",
    "5. Act based on learnt information:\n",
    "    - e.g. if a segment is price sensitive, users should get a discount to motivate them to make a purchase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da085c9f",
   "metadata": {},
   "source": [
    "# Loading modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb2e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import SpectralClustering, OPTICS, MeanShift, KMeans, MiniBatchKMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1ffc33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation class.         \n",
      "---------------------------        \n",
      "Inputted features: ['StockCode', 'InvoiceDate', 'Country', 'Quantity', 'UnitPrice', 'CustomerID'].         \n",
      "---------------------------        \n",
      "Transformation steps:         \n",
      "1. Correct data types         \n",
      "2. One Hot Encoding of ['StockCode', 'Country']         \n"
     ]
    }
   ],
   "source": [
    "import tools as t\n",
    "reload(t)\n",
    "\n",
    "from tools.preprocessing import eda\n",
    "from tools.modeling import clustering\n",
    "\n",
    "data = eda.Dataset(\n",
    "    features=['StockCode', 'InvoiceDate', 'Country', 'Quantity', 'UnitPrice', 'CustomerID'],\n",
    "    features_ohe=['StockCode', 'Country'],\n",
    ")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df80109",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb835c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = data.get_transformed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad19faf",
   "metadata": {},
   "source": [
    "# Exploratory analysis and feature engineering\n",
    "\n",
    "## Profiling variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0418059a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'get_profiling_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-eb35f26b3561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_profiling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_profiling_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_profiling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'get_profiling_df'"
     ]
    }
   ],
   "source": [
    "df_profiling = data.get_profiling_df()\n",
    "df_profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5683599",
   "metadata": {},
   "source": [
    "## Data transformation and Clustering variables\n",
    "\n",
    "These are variables that will be used in clustering algorithm.\n",
    "\n",
    "The following transformations will be applied to them:\n",
    "- Observations with missing values will be dropped.\n",
    "- One Hot Encoding will be used to encode categorical variables (`'StockCode', 'Country'`).\n",
    "- We will also break down `InvoiceDate` into Year, Month, Day.\n",
    "- `Description` will be dropped since strings can't be used in clustering algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1ba0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clustering = data.get_clustering_df()\n",
    "df_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d59bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clustering = df_clustering.iloc[:10000, :]\n",
    "df_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b6e57",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools as t\n",
    "reload(t)\n",
    "from tools.modeling import clustering\n",
    "\n",
    "clustering = clustering.Clustering(df_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e53dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'Kmeans'\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "steps = [\n",
    "#     ('scaler', StandardScaler())\n",
    "]\n",
    "plot=True\n",
    "\n",
    "model_kmeans, ypred_kmeans = clustering.check_model(name, model, steps, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ece308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clustering.loc[:,'clusters'] = ypred_kmeans\n",
    "df_clustering[['CustomerID', 'clusters']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd3502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
